Notes on: "real-time collision detection" by Christer Ericson

explicit representation,
objects represented by polygons, through their points, edges and faces

implicit representation,
geometrical objects such as spheres, cones, cylinders, tori (pl. torus), etc. which
can't be explicitly represented but implicitly through a mathematical expression:

implicit representation are usually represented as a mapping from 3d-space to 1d-real-numbers
like so:

[first, new, cool, math thing!]

f:R^3 -> R, where points given:
f(x,y,z) // our R^3
will evaluate into three regions zero, positive and negative:

f(x,y,z) = 0 // boundary of the object
f(x,y,z) > 0 // exterior of the object
f(x,y,z) < 0 // interior of the object

awesome!

Example for a sphere:
x^2 + y^2 + z^2 <= r^2    // works!

This is like a double Pythagorean theorem on the left side the resulting
distance is, if equal r^2, a point _on_ the sphere

(defun sphere-collision-p (x y z sphere-radius)
  "Returns true if the point P(x,y,z) lies within or touches the sphere of radius:
   sphere-radius."
  (<= (apply #'+
	     (mapcar #'(lambda (x) (expt x 2))
		     (list x y z)))
      (expt sphere-radius 2)))

Through understanding that this is just a double-pythagoras we can formulate a collision
test for a 2d-circle easily:
x^2 + y^2 <= r^2  (awesome number two!)

An object boundary defined in such a way is called an /implicit surface/!

Advantages:
- quick rejection culling (is it in the interior = CULL it out!)
- fast intersection test: well simply feed a point into the f(x,y,z) function and you know
  if it is inside or toughing the boundary: f(x,y,z) =< 0!

half-space,
we cut space in two along an infinite plane. The resulting two spaces left and right of
the plane are infinitely large but still just half-spaces of a bigger infinity!

convex objects (polygon),
any two points within this object can connect in a straight line without leaving the region of
the object. We need this word because collision tests are much easier with such objects!
Foreshadowing: we will probably try to break concave polygons into smaller convex objects?

concave polygon object,
opposite of convex object. Contains an interior angle greater than 180-degrees.

half-space intersection representation (convex objects only),
another way to represent polygonal objects, here we cut away some space with planes and use
the resulting half-space intersections to represent an object. An example would be to represent
a rectangle in 2d by using two x-axis values to cut away the two sides - resulting in an
infinitely long rectangle along the y axis- then provide two y-axis to encompass a finitely
big rectangle! (see texatl.cl:space for this kind of rectangle representation!)
This is reminiscent of the aabb test!

--------------------------------------------------------------------------------
We won't usually use the same geometry for collision as for rendering
Pros:
- it is usually to complex, and collision test don't need to be that precise
- the usual triangle representation of ob jets are harder to query for collision
  then other shapes like spheres, for example
- rendering data may be organized in a quite a different way than is useful for
  collision. Collision tests probably want spatial hierarchical relationships
  whereas rendering data will create topologies for adjacent vertices at best
  and material attributes, color and texture coordinates at worst (useless for
  collision tests!)
- organizing for collision tests makes the data smaller hence more efficient to
  use and coherent in memory and useful for further extension and tests tailored
  for collision
- sometimes you want to explicitly differ, for example the plane representing
  snow might be intentionally lowered in the proxy geometry to allow knee-deep
  movement in the snow. Instead for exclusion tests, just use a different geometry
  to begin with.
- even if rendering data is not needed because an object is not visible it is
  still needed for collision. Just imagine walking behind a wall, where the
  camera sees the wall it will usually cull out everything behind it, you should
  however still follow the law's of physics even when nobody is around to see it!

Cons:
- Data duplication. Could be solved by inferring the proxy geometry from the rendering
  geometry (through linearization caching)!!
- time to build the tools that generate the geometry or more time for the designer
  to create the his models
- visual consistency may suffer: objects may float above others, or fully intersect
  (surely you seen the animations which simply move through anything when they parts
   of it move outside the hitbox)
- interdependency problems: if the rendering geometry changes, the collision geometry
  might also have to change, and how is this process automated. Which of the two
  geometry comes first?

we use, hence, another geometry instead.. as a proxy:

proxy geometry,
the collision test geometry for objects. This usually reduces the complex rendering
geometry by encapsulating a object of interest into a:

bounding volume,
a simpler geometrical object like a box or a sphere representing the object in a
simpler way than the actual rendering geometry for the sake of a simpler easier
collision test!

--------------------------------------------------------------------------------
Types of queries:

interference detection or intersection testing,
yes/no did the objects collide, do they intersect?
Easy to implement, commonly used

intersection finding - WHERE did they intersect?
One contact point may sometimes suffice other times, as in rigid body simulations,
we need to detect a whole set of contact points /the contact manifold/!
Calculating the contact manifold may be difficult, and approximations may be used -
a common practice in games.

collision properties,
special collision queries, taking surface properties into account like slipperiness of a
road and climbability of a wall

penetration depth,
how deep are two objects overlapping. The problem here is what start and end point to
use to measure this. A solution to this can be the shortest movement vector needed
to separate the already interpenetrated objects. Its computation is also a difficult
problem.

/separation distance/, has a beautiful definition:
"The separation distance between two disjoint objects A and B is defined as _the minimum
of the distances between points in A and points in B_"!
Needed the predict the time (WHEN) two objects will collide. Also it poses another
problem of finding the

closest point,
in both the disjoint object A and B to each other. There can be infinite cloest points!

ETA, /estimated time of arrival/, or, more dramatic, TOI, /time of impact/

--------------------------------------------------------------------------------
pairwise collision tests for n objects, take O(n^2) time - every objects with
every other object n x n!
But we can use a divide and conquer approach:

broad phase or n-<body> processing,
use a rule to decide which objects /may/ collide. For example devide a scene into
square regions, and whenever an object is inside a given region it is mapped to
some square-region datastructure. This datastructure can then exclude all the
objects that are sole inhabitants of a region from any collision test. The
other objects under go the

narrow phase (pair processing),
perform all the pairwise test on the unconquered parts (those objects
sharing the same square region!).

--------------------------------------------------------------------------------
Sequential vs simultaneous motion,
for both we break down movement to the unit of _time step_(!). Simultaneous motion
is more realistic but more expensive to compute:
(1) determine earliest time of contact
(2) move all objects for the extend of the no-contact-time
(3) resolve the collision
(4) repeat for the extend of the time step
A problem occurs when the object moves along a surface, then a collision resolution
would take place all the time and the simulation would only advance by a small
fraction.
While broad phase grouping can help divide and conquer the problem.

An alternative simultaneous motion solution: advance the objects by a fixed small time
step, when an interpenetration of objects during a timestep occurs restore the state
before the timestep. This is also expensive.


The accuracy of simultaneous motion should be reserved for rigid-body simulations.
For most program sequential motion suffices (including games).

Sequential motion accuracy problems:
(1) Two objects during motion, in a sequential approach one object might move past the
collision point, then the other object also moves past it -> no collision occurs. (2) One
object is just behind another object, when it moves first it will catch up but if both
move at the same speed this catching up wouldn't make sense.  Both these issues _can be
solved by just making the time step smaller_!
In games the small time step is easily provided by the _high frame rate_(!)

sequential motion benefits include easy penetration resolution: just undo the single
motion during the small time step, this is to be contrasted by the simultaneous where we
have to undo motion during the a time step for _all_ the objects (possible minus some
broad phase excluded ones)!

--------------------------------------------------------------------------------
Discrete vs continuous motion

Discrete motion - static collision detection,
Collision detection is meassured at a specific time, and the objects are treated as if
they're frozen in said time (This is much cheaper than dynamic collision detection below)
The object effectively teleports from time step to time step, the collision test is hence
less precise. On the note of teleportation: the time step teleportation distance has to be
smaller than the objects spatial extend or else the object might teleport through other
objects with no collision detected, this is aptly called /tunneling/!!!

Excursion on tunneling:
To have more fun memorizing this, in quantum mechanics teleportation is an everyday thing
performed by particles all the time, called quantum tunneling. According to QM electrons
perform quantum leaps to move between between states around in an atom, as the
wave(wave-particle duality) travels around the nuclei of the atom it reinforces itself on
each iteration thereby maintaining its energy level.
Another exciting thing: scientist were able to quantum tunnel a particle over the distance
of 9meters. But this doesn't mean teleportation of humans is gonna happen soon, when prompted
for this an expert said that they had to get the particle in a particular state before
performing this, and the particles in human bodies just can't be manipulated into such
a state anytime soon.
/Excursion

dynamic collision detection,
we detect the collision by considering the continuous motion - meaning over a given time
interval or between start and end of a time step. This is both more accurate and more
expensive. More accurate because we can usually tell the exact time and point(s) of first
contact.

swept volume,
in contiuous motion, this is what we refer to the space carved out by an object as it
moves in the extend of a single time step! This can be used for the broad phase: only if
the two objects' swept volumes do intersect do they become member of the same narrow phase
group. Of course even then collision is not guaranteed (should be easy to imagine
why). But imagine an object moving in a non-trivial path during the time step, the swept
volume can then be hard to compute and work with! Fortunately such accuracy is rarely
needed, and can be reduced for simplification to a linear motion.

speedbox,
in games the swept volume is usually simplified to an elongated box covering the objects
full range of otion (or some similarly simple proxy object).


relative motion,
what-is (high-level explanation):
substracting two motion vectors hence one being stationary and the other moving towards it
for simpler intersection finding of the swept volumes. Consider v1 v2, for v1-v2, v2 is
the stationary "observer" where v1-v2 is the vector that moves towards it from v1 while,
again, v2 can't move. This explanation though is enough to work abstractly I want to
understand this at a visceral - intuitive level.
how-to (how to implement it): (TODO: test this)
given two motion vectors v1 and v2 it is virtually always better to consider the relative
motion:
vp1 vp2 are position vectors, and v1 v2 are these vectors' motion (direction) vectors
the relative motion is the substraction: v1-v2
The observer is the right-hand vector: vp2
it is immobile as vp1+(v1-v2) moves towards it (as far as the time step allows).
This is better because we now only have the swept volume carved out by vp1+(v1-v2)

Optimization,
is mainly achived by the broad phase, putting objects into regions or regio hierarchies that
may even be recursively extended when more objects govern a certain region (implementation
example: quadtree).

Robustness,
two problems: floating point inprecision and geometry nonsense through transformation. One
can give rise to other, for example: space inverting on itself, through interpolation
off-by-one bug turning into extrapolation; or trasformation order is violated and rotation
scaling distorts the geometry, or transforming normals on a non-uniform object (transpose
(inverse norm-matrix)), or systems prone to gimbal lock may have unexpected orientation at
certain stages of interpolation.  The collision system must be prepare and avoid those for..
robustness!

